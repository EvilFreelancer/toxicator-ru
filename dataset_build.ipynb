{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-23T00:29:49.004259Z",
     "start_time": "2024-04-23T00:29:48.922676Z"
    }
   },
   "source": [
    "def levenshtein_distance(s1, s2):\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein_distance(s2, s1)\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1\n",
    "            deletions = current_row[j] + 1\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    return previous_row[-1]"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T00:29:49.008319Z",
     "start_time": "2024-04-23T00:29:49.005476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def similarity_coefficient(text1, text2):\n",
    "    distance = levenshtein_distance(text1, text2)\n",
    "    max_length = max(len(text1), len(text2))\n",
    "    similarity = 1 - distance / max_length\n",
    "    return similarity"
   ],
   "id": "58c4da007325f5cd",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T00:29:49.011518Z",
     "start_time": "2024-04-23T00:29:49.009124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_similar_field(sample):\n",
    "    distances = []\n",
    "    for comment in ['neutral_comment1', 'neutral_comment2', 'neutral_comment3']:\n",
    "        if isinstance(sample[comment], float):\n",
    "            continue\n",
    "        distance = levenshtein_distance(sample[comment], sample['toxic_comment'])\n",
    "        distances.append((distance, comment))\n",
    "    distances.sort(key=lambda x: x[0])  # Sort by distance\n",
    "    return distances[0][1]  # Select the one with the minimum distance"
   ],
   "id": "f3fbd42b071a9b5f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T00:29:50.436128Z",
     "start_time": "2024-04-23T00:29:49.012209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "dev_df = pd.read_table(\"https://raw.githubusercontent.com/s-nlp/russe_detox_2022/main/data/input/dev.tsv\", sep='\\t')\n",
    "test_df = pd.read_table(\"https://raw.githubusercontent.com/s-nlp/russe_detox_2022/main/data/input/test.tsv\", sep='\\t')\n",
    "train_df = pd.read_table(\"https://raw.githubusercontent.com/s-nlp/russe_detox_2022/main/data/input/train.tsv\", sep='\\t')"
   ],
   "id": "ba08c25682a26b8f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T00:29:57.263543Z",
     "start_time": "2024-04-23T00:29:50.437016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# DEV датасет\n",
    "dev_dict = dev_df.to_dict(orient='index')\n",
    "dev_samples = []\n",
    "for sample in dev_dict:\n",
    "    closest_neutral_comment = get_similar_field(dev_dict[sample])\n",
    "    prepared = {\n",
    "        \"instruction\": \"Перефразируй нетоксичный текст так, чтобы он стал токсичным, сохраняя при этом исходный смысл, орфографию и пунктуацию.\",\n",
    "        \"input\": dev_dict[sample][closest_neutral_comment],\n",
    "        \"output\": dev_dict[sample]['toxic_comment'],\n",
    "    }\n",
    "    dev_samples.append(prepared)\n",
    "\n",
    "# TEST датасет\n",
    "test_dict = test_df.to_dict(orient='index')\n",
    "test_samples = []\n",
    "for sample in test_dict:\n",
    "    prepared = {\n",
    "        \"instruction\": \"Перефразируй нетоксичный текст так, чтобы он стал токсичным, сохраняя при этом исходный смысл, орфографию и пунктуацию.\",\n",
    "        \"input\": '',\n",
    "        \"output\": test_dict[sample]['toxic_comment'],\n",
    "    }\n",
    "    test_samples.append(prepared)\n",
    "\n",
    "# TRAIN датасет\n",
    "train_dict = train_df.to_dict(orient='index')\n",
    "train_samples = []\n",
    "for sample in train_dict:\n",
    "    closest_neutral_comment = get_similar_field(train_dict[sample])\n",
    "    prepared = {\n",
    "        \"instruction\": \"Перефразируй нетоксичный текст так, чтобы он стал токсичным, сохраняя при этом исходный смысл, орфографию и пунктуацию.\",\n",
    "        \"input\": train_dict[sample][closest_neutral_comment],\n",
    "        \"output\": train_dict[sample]['toxic_comment'],\n",
    "    }\n",
    "    train_samples.append(prepared)"
   ],
   "id": "c88e7cf86e4fc8a5",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T00:36:01.089738Z",
     "start_time": "2024-04-23T00:35:56.620306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Объединение отдельных датасетов в один датасет с разными сплитами\n",
    "dataset_dict = DatasetDict({\n",
    "    'dev': Dataset.from_list(dev_samples),\n",
    "    'test': Dataset.from_list(test_samples),\n",
    "    'train': Dataset.from_list(train_samples)\n",
    "})\n",
    "\n",
    "# Выгрузка датасета на Hugging Face\n",
    "dataset_dict.push_to_hub('evilfreelancer/toxicator-ru')"
   ],
   "id": "c6256f931a37dae0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e6b89a2d61084632aaa2adbc4596655a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7e837c22bdd54cf18113325fb2f77ad0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "71f15aa3a52c47feaf7b351840ebc611"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "add6c9e760274bc7beb437ec6b595c9d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "865029ee435848d787a183cbe5626643"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/7 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "38630e710842464595fe97f8dbedf414"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/evilfreelancer/toxicator-ru/commit/4392d60d6e40119d6de9c2d80ec530b798647bb5', commit_message='Upload dataset', commit_description='', oid='4392d60d6e40119d6de9c2d80ec530b798647bb5', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
